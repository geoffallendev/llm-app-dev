{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3420575b-4d00-458b-aa0e-7030008ccd53",
   "metadata": {},
   "source": [
    "## Creating an index and populating it with documents using PostgreSQL+pgvector\n",
    "\n",
    "Simple example on how to ingest PDF documents, then web pages content into a PostgreSQL+pgvector VectorStore.\n",
    "\n",
    "Requirements:\n",
    "- A PostgreSQL cluster with the pgvector extension installed (https://github.com/pgvector/pgvector)\n",
    "- A Database created in the cluster with the extension enabled (in this example, the database is named `vectordb`. Run the following command in the database as a superuser:\n",
    "`CREATE EXTENSION vector;`\n",
    "\n",
    "Note: if your PostgreSQL is deployed on OpenShift, directly from inside the Pod (Terminal view on the Console, or using `oc rsh` to log into the Pod), you can run the command: `psql -d vectordb -c \"CREATE EXTENSION vector;\"`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8308b229-b520-4e82-a783-eb921bb955e7",
   "metadata": {},
   "source": [
    "### Needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91e41b41-f60a-4b0f-91a1-cd273b60f21b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pgvector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a82063d-6153-4812-8977-042241736b53",
   "metadata": {},
   "source": [
    "### Base parameters, the PostgreSQL info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "417ed4a4-9418-4f48-bebd-ef0ea11ae434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "product_version = 2.6\n",
    "CONNECTION_STRING = \"postgresql+psycopg://vectordb:vectordb@postgresql.postgresql.svc.cluster.local:5432/vectordb\"\n",
    "COLLECTION_NAME = f\"rhoai-doc-{product_version}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b499a49-128c-4be5-903b-76c40771c7bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "600cd763-6ecc-4c77-89c0-47108c31c44e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader, WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.pgvector import PGVector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68f6785-480e-4519-be4f-8e1738dba4ca",
   "metadata": {},
   "source": [
    "## Initial index creation and document ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cff5f7-c509-48db-90b5-e15815b8b530",
   "metadata": {},
   "source": [
    "#### Download and load pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc4fe0db-f494-4cbd-9e97-8b6359a78cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"release_notes\",\n",
    "    \"introduction_to_red_hat_openshift_ai\",\n",
    "    \"getting_started_with_red_hat_openshift_ai_self-managed\",\n",
    "    \"openshift_ai_tutorial_-_fraud_detection_example\",\n",
    "    \"developing_a_model\",\n",
    "    \"integrating_data_from_amazon_s3\",\n",
    "    \"working_on_data_science_projects\",\n",
    "    \"serving_models\",\n",
    "    \"monitoring_data_science_models\",\n",
    "    \"managing_users\",\n",
    "    \"managing_resources\",\n",
    "    \"installing_and_uninstalling_openshift_ai_self-managed\",\n",
    "    \"installing_and_uninstalling_openshift_ai_self-managed_in_a_disconnected_environment\",\n",
    "    \"upgrading_openshift_ai_self-managed\",\n",
    "    \"upgrading_openshift_ai_self-managed_in_a_disconnected_environment\",   \n",
    "]\n",
    "\n",
    "pdfs = [f\"https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/{product_version}/pdf/{doc}/red_hat_openshift_ai_self-managed-{product_version}-{doc}-en-us.pdf\" for doc in documents]\n",
    "pdfs_to_urls = {f\"red_hat_openshift_ai_self-managed-{product_version}-{doc}-en-us\": f\"https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/{product_version}/html-single/{doc}/index\" for doc in documents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc4c5ef7-35f1-4ef9-91e0-a56e990c5de7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "    \n",
    "rhel_pdf_urls = [\n",
    "        'https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/pdf/performing_a_standard_rhel_9_installation/red_hat_enterprise_linux-9-performing_a_standard_rhel_9_installation-en-us.pdf',\n",
    "        'https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/pdf/performing_an_advanced_rhel_9_installation/red_hat_enterprise_linux-9-performing_an_advanced_rhel_9_installation-en-us.pdf',\n",
    "        'https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/pdf/configuring_basic_system_settings/red_hat_enterprise_linux-9-configuring_basic_system_settings-en-us.pdf',\n",
    "        'https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/pdf/security_hardening/red_hat_enterprise_linux-9-security_hardening-en-us.pdf',\n",
    "        'https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/pdf/composing_a_customized_rhel_system_image/red_hat_enterprise_linux-9-composing_a_customized_rhel_system_image-en-us.pdf',\n",
    "        'https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/pdf/configuring_and_managing_networking/red_hat_enterprise_linux-9-configuring_and_managing_networking-en-us.pdf',\n",
    "        'https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/pdf/upgrading_from_rhel_8_to_rhel_9/red_hat_enterprise_linux-9-upgrading_from_rhel_8_to_rhel_9-en-us.pdf',\n",
    "]\n",
    "    \n",
    "\n",
    "os.mkdir(\"rhel-doc\")\n",
    "\n",
    "for pdf in rhel_pdf_urls:\n",
    "    try:\n",
    "        response = requests.get(pdf)\n",
    "    except:\n",
    "        print(f\"Skipped {pdf}\")\n",
    "        continue\n",
    "    if response.status_code!=200:\n",
    "        print(f\"Skipped {pdf}\")\n",
    "        continue  \n",
    "    with open(f\"rhel-doc/{pdf.split('/')[-1]}\", 'wb') as f:\n",
    "        f.write(response.content)  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eea5acc-49df-41c9-a01a-0cdbca96e8e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'rhoai-doc-2.6'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrhoai-doc-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mproduct_version\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pdf \u001b[38;5;129;01min\u001b[39;00m pdfs:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'rhoai-doc-2.6'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "os.mkdir(f\"rhoai-doc-{product_version}\")\n",
    "\n",
    "for pdf in pdfs:\n",
    "    try:\n",
    "        response = requests.get(pdf)\n",
    "    except:\n",
    "        print(f\"Skipped {pdf}\")\n",
    "        continue\n",
    "    if response.status_code!=200:\n",
    "        print(f\"Skipped {pdf}\")\n",
    "        continue  \n",
    "    with open(f\"rhoai-doc-{product_version}/{pdf.split('/')[-1]}\", 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af4074d4-eff4-45b2-902d-ec8c075a83ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf_folder_path = f\"./rhoai-doc-{product_version}\"\n",
    "\n",
    "pdf_loader = PyPDFDirectoryLoader(pdf_folder_path)\n",
    "pdf_docs = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f32bce85-5ce6-4d12-a36c-6efd4e165451",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf_folder_path = \"rhel-doc/\"\n",
    "\n",
    "pdf_loader = PyPDFDirectoryLoader(pdf_folder_path)\n",
    "pdf_docs = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde7ed3a-0530-47a1-95c2-22db6c782a95",
   "metadata": {},
   "source": [
    "#### Inject metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "702230f6-e6d3-44c7-a643-4996387606ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "for doc in pdf_docs:\n",
    "    doc.metadata[\"source\"] = Path(doc.metadata[\"source\"]).stem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd511d44-2d92-47a0-9163-b25576c9557b",
   "metadata": {},
   "source": [
    "#### Load websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8aebf003-d7ec-43ba-8e04-1931bcff2866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "websites = [\n",
    "    \"https://ai-on-openshift.io/getting-started/openshift/\",\n",
    "    \"https://ai-on-openshift.io/getting-started/opendatahub/\",\n",
    "    \"https://ai-on-openshift.io/getting-started/openshift-ai/\",\n",
    "    \"https://ai-on-openshift.io/odh-rhoai/configuration/\",\n",
    "    \"https://ai-on-openshift.io/odh-rhoai/custom-notebooks/\",\n",
    "    \"https://ai-on-openshift.io/odh-rhoai/nvidia-gpus/\",\n",
    "    \"https://ai-on-openshift.io/odh-rhoai/custom-runtime-triton/\",\n",
    "    \"https://ai-on-openshift.io/odh-rhoai/openshift-group-management/\",\n",
    "    \"https://ai-on-openshift.io/tools-and-applications/minio/minio/\",\n",
    "    \"https://access.redhat.com/articles/7047935\",\n",
    "    \"https://access.redhat.com/articles/rhoai-supported-configs\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99f41110-8ca7-4d90-93b2-3b5021c894b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "website_loader = WebBaseLoader(websites)\n",
    "website_docs = website_loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157ddd29-54b3-474a-9b10-2d274bc3254f",
   "metadata": {},
   "source": [
    "#### Merge both types of docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d361094-8b43-4351-8495-37628c35c42d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = pdf_docs + website_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4198fe0a-38bf-4cd4-af7d-35b41c645edd",
   "metadata": {},
   "source": [
    "#### Split documents into chunks with some overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edba4a08-2194-4df1-9091-6f2b596757a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Red Hat Enterprise Linux\\n \\n9\\nSecurity hardening\\nEnhancing security of Red Hat Enterprise Linux 9 systems\\nLast Updated: 2024-04-03', metadata={'source': 'red_hat_enterprise_linux-9-security_hardening-en-us', 'page': 0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024,\n",
    "                                               chunk_overlap=40)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "all_splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6884f070",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Cleanup documents as PostgreSQL won't accept the NUL character, '\\x00', in TEXT fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5aefc08d-a4ad-4aad-9120-cfa98b67cbe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for doc in all_splits:\n",
    "    doc.page_content = doc.page_content.replace('\\x00', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae7eae2-c670-4eb5-803b-b4d591fa83db",
   "metadata": {},
   "source": [
    "#### Create the index and ingest the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bbb6a3e3-5ccd-441e-b80d-427555d9e9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "db = PGVector.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=embeddings,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    #pre_delete_collection=True # This deletes existing collection and its data, use carefully!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3d987b-8ebc-46ce-a206-48c1339b7a5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Alternatively, add new documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f227d-a13d-456c-b91b-3c203e62fc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "# db = PGVector(\n",
    "#     connection_string=CONNECTION_STRING,\n",
    "#     collection_name=COLLECTION_NAME,\n",
    "#     embedding_function=embeddings)\n",
    "\n",
    "# db.add_documents(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae3b458-4979-46df-8493-7496764a2568",
   "metadata": {},
   "source": [
    "#### Test query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "489c6e6d-c42c-4de4-87cf-8edfd0e63da3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"How do you install OpenShift Data Science?\"\n",
    "#query = \"How can I upgrade from rhel 8 to rhel 9?\"\n",
    "docs_with_score = db.similarity_search_with_score(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90feeb37-7888-4c5f-a5cb-5f82637cec16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Score:  0.29386721289949214\n",
      "Installing the Red Hat OpenShift AI Operator\n",
      ".\n",
      "4\n",
      ". \n",
      "Install OpenShift AI components. See \n",
      "Installing and managing Red Hat OpenShift AI\n",
      "components\n",
      ".\n",
      "5\n",
      ". \n",
      "Configure user and administrator groups to provide user access to OpenShift AI. See \n",
      "Adding\n",
      "users\n",
      ".\n",
      "6\n",
      ". \n",
      "Access the OpenShift AI dashboard. See \n",
      "Accessing the OpenShift AI dashboard\n",
      ".\n",
      "7\n",
      ". \n",
      "Optionally, enable graphics processing units (GPUs) in OpenShift AI to ensure that your data\n",
      "scientists can use compute-heavy workloads in their models. See \n",
      "Enabling GPU support in\n",
      "OpenShift AI\n",
      ".\n",
      "Red Hat OpenShift AI Self-Managed 2.6 Installing and uninstalling OpenShift AI Self-Managed\n",
      "6\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.29386721289949214\n",
      "Installing the Red Hat OpenShift AI Operator\n",
      ".\n",
      "4\n",
      ". \n",
      "Install OpenShift AI components. See \n",
      "Installing and managing Red Hat OpenShift AI\n",
      "components\n",
      ".\n",
      "5\n",
      ". \n",
      "Configure user and administrator groups to provide user access to OpenShift AI. See \n",
      "Adding\n",
      "users\n",
      ".\n",
      "6\n",
      ". \n",
      "Access the OpenShift AI dashboard. See \n",
      "Accessing the OpenShift AI dashboard\n",
      ".\n",
      "7\n",
      ". \n",
      "Optionally, enable graphics processing units (GPUs) in OpenShift AI to ensure that your data\n",
      "scientists can use compute-heavy workloads in their models. See \n",
      "Enabling GPU support in\n",
      "OpenShift AI\n",
      ".\n",
      "Red Hat OpenShift AI Self-Managed 2.6 Installing and uninstalling OpenShift AI Self-Managed\n",
      "6\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.30611960255386694\n",
      "CHAPTER 6. INSTALLING AND MANAGING RED HAT\n",
      "OPENSHIFT AI COMPONENTS\n",
      "The following procedures show how to use the command-line interface (CLI) and OpenShift Container\n",
      "Platform web console to install and manage components of Red Hat OpenShift AI on your OpenShift\n",
      "Container Platform cluster.\n",
      "6.1. INSTALLING RED HAT OPENSHIFT AI COMPONENTS BY USING\n",
      "THE CLI\n",
      "The following procedure shows how to use the OpenShift command-line interface (CLI) to install\n",
      "specific components of Red Hat OpenShift AI on your OpenShift Container Platform cluster.\n",
      "IMPORTANT\n",
      "The following procedure describes how to create and configure a \n",
      "DataScienceCluster\n",
      "object to install Red Hat OpenShift AI components as part of a \n",
      "new\n",
      " installation. However,\n",
      "if you upgraded from version 1 of OpenShift AI (previously OpenShift Data Science), the\n",
      "upgrade process automatically created a default \n",
      "DataScienceCluster\n",
      " object. If you\n",
      "upgraded from version 2.4 to 2.5, the upgrade process uses the settings from the 2.4\n",
      "version’s \n",
      "DataScienceCluster\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.30611960255386694\n",
      "CHAPTER 6. INSTALLING AND MANAGING RED HAT\n",
      "OPENSHIFT AI COMPONENTS\n",
      "The following procedures show how to use the command-line interface (CLI) and OpenShift Container\n",
      "Platform web console to install and manage components of Red Hat OpenShift AI on your OpenShift\n",
      "Container Platform cluster.\n",
      "6.1. INSTALLING RED HAT OPENSHIFT AI COMPONENTS BY USING\n",
      "THE CLI\n",
      "The following procedure shows how to use the OpenShift command-line interface (CLI) to install\n",
      "specific components of Red Hat OpenShift AI on your OpenShift Container Platform cluster.\n",
      "IMPORTANT\n",
      "The following procedure describes how to create and configure a \n",
      "DataScienceCluster\n",
      "object to install Red Hat OpenShift AI components as part of a \n",
      "new\n",
      " installation. However,\n",
      "if you upgraded from version 1 of OpenShift AI (previously OpenShift Data Science), the\n",
      "upgrade process automatically created a default \n",
      "DataScienceCluster\n",
      " object. If you\n",
      "upgraded from version 2.4 to 2.5, the upgrade process uses the settings from the 2.4\n",
      "version’s \n",
      "DataScienceCluster\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for doc, score in docs_with_score:\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Score: \", score)\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd97b510-21ec-4e35-a768-1e977a948f86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
